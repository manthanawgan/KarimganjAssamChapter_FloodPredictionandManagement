{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhHRasRcTKcX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score # Import r2_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgXhufi48UNY"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8zpG3NLTHCN"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"AllData_After_EDA.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "# Remove timezone info if it exists\n",
        "df.index = df.index.tz_localize(None)\n",
        "df.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2vmPftnW-JD"
      },
      "outputs": [],
      "source": [
        "# Extract features (X) and target variable (y)\n",
        "X = df.drop(columns=['flooded'])  # Drop Date & Target column\n",
        "y = df['flooded']\n",
        "\n",
        "# Split into initial train-test sets (before resampling)\n",
        "train_size = 0.8  # 80% for training, 20% for testing\n",
        "split_index = int(len(df) * train_size)\n",
        "\n",
        "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
        "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8PPTYa7_WFH",
        "outputId": "73e7f203-675e-4bae-c032-a8c50969bdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    2527\n",
            "1    1193\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def windowed_resampling(X_train, y_train, window_size='15D', max_copies=1):\n",
        "    \"\"\"\n",
        "    Oversamples the minority class using windowed resampling.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: Feature DataFrame with datetime index.\n",
        "    - y_train: Target Series with datetime index.\n",
        "    - window_size: Time delta defining the window size (e.g., '3D' for 3 days).\n",
        "    - max_copies: Maximum number of times a sample can be duplicated.\n",
        "\n",
        "    Returns:\n",
        "    - Resampled X_train and y_train.\n",
        "    \"\"\"\n",
        "    # Convert the index to DatetimeIndex if it's not already\n",
        "    X_train.index = pd.to_datetime(X_train.index)\n",
        "    y_train.index = pd.to_datetime(y_train.index)\n",
        "\n",
        "    X_resampled = X_train.copy()\n",
        "    y_resampled = y_train.copy()\n",
        "\n",
        "    minority_class_idx = y_train[y_train == 1].index\n",
        "\n",
        "    for idx in minority_class_idx:\n",
        "        for _ in range(min(np.random.randint(1, max_copies + 1), max_copies)):\n",
        "            window_start = idx - pd.Timedelta(window_size)\n",
        "            window_end = idx + pd.Timedelta(window_size)\n",
        "\n",
        "            sampled_row = X_train.loc[idx].copy()\n",
        "            sampled_label = y_train.loc[idx]\n",
        "\n",
        "            sampled_row.name = idx  # Keep the datetime index\n",
        "            X_resampled = pd.concat([X_resampled, sampled_row.to_frame().T])\n",
        "            y_resampled = pd.concat([y_resampled, pd.Series(sampled_label, index=[idx])])\n",
        "\n",
        "    return X_resampled.sort_index(), y_resampled.sort_index()\n",
        "\n",
        "# Example usage with your dataset\n",
        "X_train_resampled, y_train_resampled = windowed_resampling(X_train, y_train, window_size='3D', max_copies=3)\n",
        "print(y_train_resampled.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Direct Prediction"
      ],
      "metadata": {
        "id": "qB0vMvicy94G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jbz81oUW2zz"
      },
      "source": [
        "## Trying Supervised Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6DeHnjXOm2"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9trF3HzXNMI",
        "outputId": "41ac89ab-1e5f-4bf7-bb5b-c0c3eceb67cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.8043775649794802\n",
            "Confusion Matrix:\n",
            " [[527 143]\n",
            " [  0  61]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.79      0.88       670\n",
            "           1       0.30      1.00      0.46        61\n",
            "\n",
            "    accuracy                           0.80       731\n",
            "   macro avg       0.65      0.89      0.67       731\n",
            "weighted avg       0.94      0.80      0.85       731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "logreg_model = LogisticRegression(max_iter=1000)\n",
        "logreg_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_logreg = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logreg))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logreg))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQjqB57cXsLf"
      },
      "source": [
        "## RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnGIAdYQXqYy",
        "outputId": "c1dba2f1-552d-42dd-8694-76bd61773efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.893296853625171\n",
            "Confusion Matrix:\n",
            " [[628  42]\n",
            " [ 36  25]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94       670\n",
            "           1       0.37      0.41      0.39        61\n",
            "\n",
            "    accuracy                           0.89       731\n",
            "   macro avg       0.66      0.67      0.67       731\n",
            "weighted avg       0.90      0.89      0.90       731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "mOeRRDxfYDlP",
        "outputId": "551b1677-ee0b-409b-d994-2f1bfab436cc"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-6caaebd2c949>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid_search_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrid_search_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Best parameters and score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         tree._fit(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             self.tree_ = Tree(\n",
            "\u001b[0;32m_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m     \"\"\"\n\u001b[0;32m-> 2810\u001b[0;31m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[1;32m   2811\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[1;32m     73\u001b[0m                   if v is not np._NoValue}\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Random Forest Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters for Random Forest:\", grid_search_rf.best_params_)\n",
        "print(\"Best Accuracy for Random Forest:\", grid_search_rf.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc2nvwrrZM57",
        "outputId": "943e9608-1cca-4631-f7f1-abd13d08a0f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy for XGBoost: 0.9042407660738714\n",
            "Confusion Matrix:\n",
            " [[644  26]\n",
            " [ 44  17]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       670\n",
            "           1       0.40      0.28      0.33        61\n",
            "\n",
            "    accuracy                           0.90       731\n",
            "   macro avg       0.67      0.62      0.64       731\n",
            "weighted avg       0.89      0.90      0.90       731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the best model\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "print(\"Test Accuracy for XGBoost:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfsAaIbLX0fY"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np4hP88MXy-K",
        "outputId": "e942cf76-374a-4b58-bc48-615b057f70d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.8645690834473324\n",
            "Confusion Matrix:\n",
            " [[579  91]\n",
            " [  8  53]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.86      0.92       670\n",
            "           1       0.37      0.87      0.52        61\n",
            "\n",
            "    accuracy                           0.86       731\n",
            "   macro avg       0.68      0.87      0.72       731\n",
            "weighted avg       0.93      0.86      0.89       731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# XGBoost Classifier\n",
        "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
        "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbPIxcFsYesK",
        "outputId": "005f0228-5121-419e-9644-af11de9c3d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8748 candidates, totalling 26244 fits\n",
            "Best Parameters for XGBoost: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'scale_pos_weight': 7, 'subsample': 0.8}\n",
            "Best F1-score for XGBoost: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'scale_pos_weight': [5, 7, 9, 11]  # Adjusting for class imbalance\n",
        "}\n",
        "\n",
        "xgb_model = XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           scoring='recall', cv=cv_strategy, verbose=2, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"Best Parameters for XGBoost:\", grid_search.best_params_)\n",
        "print(\"Best F1-score for XGBoost:\", grid_search.best_score_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1tug47qOYlNd",
        "outputId": "2372f0c1-2807-45a8-b341-f43fd1138cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy for XGBoost: 0.5129958960328317\n",
            "Confusion Matrix:\n",
            " [[314 356]\n",
            " [  0  61]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.47      0.64       670\n",
            "           1       0.15      1.00      0.26        61\n",
            "\n",
            "    accuracy                           0.51       731\n",
            "   macro avg       0.57      0.73      0.45       731\n",
            "weighted avg       0.93      0.51      0.61       731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the best model\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "print(\"Test Accuracy for XGBoost:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ttf7BzopYe_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "930912ba-a8ce-45a9-ae04-5bd58b6d62eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8748 candidates, totalling 26244 fits\n",
            "Best Parameters for XGBoost: {'colsample_bytree': 0.7, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'scale_pos_weight': 7, 'subsample': 1.0}\n",
            "Best F1-score for XGBoost: 0.9999969268403617\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'scale_pos_weight': [5, 7, 9, 11]  # Adjusting for class imbalance\n",
        "}\n",
        "\n",
        "xgb_model = XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           scoring='roc_auc', cv=cv_strategy, verbose=2, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(\"Best Parameters for XGBoost:\", grid_search.best_params_)\n",
        "print(\"Best F1-score for XGBoost:\", grid_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf9NytJtYsNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ad609e-5494-4c55-f805-d72d3d13228d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for XGBoost: 0.8057455540355677\n",
            "Confusion Matrix:\n",
            " [[537 133]\n",
            " [  9  52]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.80      0.88       670\n",
            "           1       0.28      0.85      0.42        61\n",
            "\n",
            "    accuracy                           0.81       731\n",
            "   macro avg       0.63      0.83      0.65       731\n",
            "weighted avg       0.92      0.81      0.84       731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the best model\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "print(\"Test Accuracy for XGBoost:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yb5xc4rYwtP"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VAZjCQEZg4f",
        "outputId": "100a8568-9b27-4c35-a510-8d239b935ac5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-97-cca25d9d748d>:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  y_seq.append(y[i+time_steps])  # Predict the next day's flood status\n"
          ]
        }
      ],
      "source": [
        "def create_sequences(X, y, time_steps=10):\n",
        "    X_seq, y_seq = [], []\n",
        "\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_seq.append(X[i:i+time_steps])  # Collect the last 5 days of data\n",
        "        y_seq.append(y[i+time_steps])  # Predict the next day's flood status\n",
        "\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# Create sequences for training and testing\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test, y_test)\n",
        "\n",
        "\n",
        "# Scaling the training data\n",
        "scaler = StandardScaler()\n",
        "X_train_seq_scaled = scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[-1])).reshape(X_train_seq.shape)\n",
        "\n",
        "# Apply the same scaling to the test data\n",
        "X_test_seq_scaled = scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[-1])).reshape(X_test_seq.shape)\n",
        "\n",
        "train_size_seq = int(len(X_train_seq_scaled) * 0.8)  # 70% for training, 30% for validation\n",
        "\n",
        "X_train_seq_final, X_val_seq = X_train_seq_scaled[:train_size_seq], X_train_seq_scaled[train_size_seq:]\n",
        "y_train_seq_final, y_val_seq = y_train_seq[:train_size_seq], y_train_seq[train_size_seq:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8DiybW2mwPU",
        "outputId": "0177bbf4-b6c3-42b6-db4f-43129f8dccdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.13547724940130004"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.sum() / y_train.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIWDEQRAfSU4"
      },
      "outputs": [],
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')  # Convert labels to float32\n",
        "    y_pred = K.round(y_pred)  # Convert probabilities to 0/1\n",
        "\n",
        "    tp = K.sum(y_true * y_pred)  # True positives\n",
        "    precision = tp / (K.sum(y_pred) + K.epsilon())  # Avoid division by zero\n",
        "    recall = tp / (K.sum(y_true) + K.epsilon())  # Avoid division by zero\n",
        "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "\n",
        "# Define focal loss function\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        bce = BinaryCrossentropy()(y_true, y_pred)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        return K.mean(alpha * K.pow((1 - p_t), gamma) * bce)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_ziNAUPb4Vy"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Add LSTM layer\n",
        "model.add(LSTM(units=64, activation='relu', input_shape=(X_train_seq_scaled.shape[1], X_train_seq_scaled.shape[2]), return_sequences=False))\n",
        "\n",
        "# Add a dropout layer for regularization\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Add output layer for binary classification (sigmoid activation)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=focal_loss(), metrics=[f1_score])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl-0IVgpcKDa",
        "outputId": "eab8a866-5bc3-46fc-f429-f663bce36300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - f1_score: 0.4938 - loss: 0.0144 - val_f1_score: 0.0000e+00 - val_loss: 0.0314\n",
            "Epoch 2/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - f1_score: 0.6177 - loss: 0.0055 - val_f1_score: 0.0000e+00 - val_loss: 0.0836\n",
            "Epoch 3/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - f1_score: 3.1739 - loss: 0.0042 - val_f1_score: 0.0000e+00 - val_loss: 0.0749\n",
            "Epoch 4/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - f1_score: 3.7177 - loss: 0.0027 - val_f1_score: 0.0000e+00 - val_loss: 0.1570\n",
            "Epoch 5/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - f1_score: 3.5676 - loss: 0.0024 - val_f1_score: 0.0000e+00 - val_loss: 0.5923\n",
            "Epoch 6/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - f1_score: 3.6132 - loss: 0.0023 - val_f1_score: 0.0000e+00 - val_loss: 0.9581\n",
            "Epoch 7/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - f1_score: 3.8660 - loss: 0.0014 - val_f1_score: 0.0000e+00 - val_loss: 1.2930\n",
            "Epoch 8/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - f1_score: 3.7916 - loss: 0.0013 - val_f1_score: 0.0000e+00 - val_loss: 1.9313\n",
            "Epoch 9/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - f1_score: 3.9808 - loss: 6.7447e-04 - val_f1_score: 0.0000e+00 - val_loss: 1.9654\n",
            "Epoch 10/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - f1_score: 4.7565 - loss: 8.3093e-04 - val_f1_score: 0.0000e+00 - val_loss: 1.7856\n",
            "Epoch 11/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - f1_score: 4.0636 - loss: 6.8866e-04 - val_f1_score: 0.0000e+00 - val_loss: 2.2184\n",
            "Epoch 12/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - f1_score: 4.1499 - loss: 6.1198e-04 - val_f1_score: 0.0000e+00 - val_loss: 2.0560\n",
            "Epoch 13/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - f1_score: 3.8802 - loss: 4.1998e-04 - val_f1_score: 0.0000e+00 - val_loss: 2.2982\n",
            "Epoch 14/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - f1_score: 4.0732 - loss: 2.6256e-04 - val_f1_score: 0.0000e+00 - val_loss: 2.0933\n",
            "Epoch 15/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - f1_score: 4.3263 - loss: 5.6480e-04 - val_f1_score: 0.0000e+00 - val_loss: 2.6340\n",
            "Epoch 16/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - f1_score: 4.5307 - loss: 4.9637e-04 - val_f1_score: 0.0000e+00 - val_loss: 2.9004\n",
            "Epoch 17/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - f1_score: 4.1822 - loss: 2.3282e-04 - val_f1_score: 0.0000e+00 - val_loss: 3.0073\n",
            "Epoch 18/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - f1_score: 4.2746 - loss: 3.5180e-04 - val_f1_score: 0.0000e+00 - val_loss: 2.8332\n",
            "Epoch 19/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - f1_score: 4.1595 - loss: 2.7175e-04 - val_f1_score: 0.0000e+00 - val_loss: 3.0161\n",
            "Epoch 20/20\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - f1_score: 4.2979 - loss: 2.4799e-04 - val_f1_score: 0.0000e+00 - val_loss: 2.8522\n"
          ]
        }
      ],
      "source": [
        "#train the model\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_seq), y=y_train_seq)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "history = model.fit(X_train_seq_final, y_train_seq_final, epochs=20, batch_size=32,  class_weight=class_weights,validation_data=(X_val_seq, y_val_seq), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8nWv1blcSCU",
        "outputId": "d3325bca-b22d-45e8-e8d5-62598eb44411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Test Accuracy: 0.9153952843273232\n",
            "Confusion Matrix:\n",
            " [[660   0]\n",
            " [ 61   0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96       660\n",
            "           1       0.00      0.00      0.00        61\n",
            "\n",
            "    accuracy                           0.92       721\n",
            "   macro avg       0.46      0.50      0.48       721\n",
            "weighted avg       0.84      0.92      0.87       721\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_seq_scaled)\n",
        "y_pred = (y_pred > 0.5)  # Convert probabilities to binary classification\n",
        "\n",
        "# Evaluate performance\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test_seq, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_seq, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_seq, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJP4S572kUB-"
      },
      "source": [
        "### Isolation Forest  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFKnEwgoitXG"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Fit the Isolation Forest model on the training data\n",
        "model = IsolationForest(contamination=0.15)  # contamination is the expected proportion of anomalies\n",
        "model.fit(X_train_seq_scaled.reshape(X_train_seq_scaled.shape[0], -1))  # Flattening the time-series data\n",
        "y_pred = model.predict(X_test_seq_scaled.reshape(X_test_seq_scaled.shape[0], -1))\n",
        "\n",
        "# Convert predictions: 1 for normal, -1 for anomalies (flooded)\n",
        "y_pred = [1 if i == 1 else 0 for i in y_pred]  # Convert to 0 (non-flooded) and 1 (flooded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB7VoGCykhAl",
        "outputId": "2ea8f8cd-3cd1-4865-ef19-b74740015a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.30578512396694213\n",
            "Confusion Matrix:\n",
            " [[184 481]\n",
            " [ 23  38]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.28      0.42       665\n",
            "           1       0.07      0.62      0.13        61\n",
            "\n",
            "    accuracy                           0.31       726\n",
            "   macro avg       0.48      0.45      0.28       726\n",
            "weighted avg       0.82      0.31      0.40       726\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy:\", accuracy_score(y_test_seq, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_seq, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_seq, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHHV-Asmk8qx"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJNw1qmmk-u9"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "# Fit the One-Class SVM model on the training data\n",
        "model = OneClassSVM(nu=0.1, kernel='rbf', gamma='scale')\n",
        "model.fit(X_train_seq_scaled.reshape(X_train_seq_scaled.shape[0], -1))\n",
        "y_pred = model.predict(X_test_seq_scaled.reshape(X_test_seq_scaled.shape[0], -1))\n",
        "\n",
        "# Convert predictions: 1 for normal, -1 for anomalies (flooded)\n",
        "y_pred = [1 if i == 1 else 0 for i in y_pred]  # Convert to 0 (non-flooded) and 1 (flooded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1TxashwklTk",
        "outputId": "22dc45aa-b713-46e7-ae53-8ba6d6bf7fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.6101928374655647\n",
            "Confusion Matrix:\n",
            " [[434 231]\n",
            " [ 52   9]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.65      0.75       665\n",
            "           1       0.04      0.15      0.06        61\n",
            "\n",
            "    accuracy                           0.61       726\n",
            "   macro avg       0.47      0.40      0.41       726\n",
            "weighted avg       0.82      0.61      0.70       726\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy:\", accuracy_score(y_test_seq, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_seq, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_seq, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuX1G4KClW4x"
      },
      "source": [
        "### LOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3cv89bslTG-"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Fit the LOF model on the training data\n",
        "model = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
        "y_pred = model.fit_predict(X_test_seq_scaled.reshape(X_test_seq_scaled.shape[0], -1))\n",
        "\n",
        "# Convert predictions: 1 for normal, -1 for anomalies (flooded)\n",
        "y_pred = [1 if i == 1 else 0 for i in y_pred]  # Convert to 0 (non-flooded) and 1 (flooded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeiGq7islbQp",
        "outputId": "06c76848-0c6e-4df4-e0f3-7f872359a9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.1790633608815427\n",
            "Confusion Matrix:\n",
            " [[ 71 594]\n",
            " [  2  59]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.11      0.19       665\n",
            "           1       0.09      0.97      0.17        61\n",
            "\n",
            "    accuracy                           0.18       726\n",
            "   macro avg       0.53      0.54      0.18       726\n",
            "weighted avg       0.90      0.18      0.19       726\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy:\", accuracy_score(y_test_seq, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_seq, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_seq, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4jbz81oUW2zz",
        "0Yb5xc4rYwtP",
        "LJP4S572kUB-",
        "QHHV-Asmk8qx",
        "vuX1G4KClW4x"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}